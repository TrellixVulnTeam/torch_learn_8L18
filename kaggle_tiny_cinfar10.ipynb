{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "15d4cb59-5737-4f61-b7e6-11d53c634946",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-29T15:50:23.778439Z",
     "iopub.status.busy": "2022-05-29T15:50:23.777524Z",
     "iopub.status.idle": "2022-05-29T15:50:23.785761Z",
     "shell.execute_reply": "2022-05-29T15:50:23.784769Z",
     "shell.execute_reply.started": "2022-05-29T15:50:23.778385Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from multiprocessing import freeze_support\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dfd2699d-ed43-401c-b46c-2f066069ec3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-29T15:50:24.764934Z",
     "iopub.status.busy": "2022-05-29T15:50:24.764355Z",
     "iopub.status.idle": "2022-05-29T15:50:24.778704Z",
     "shell.execute_reply": "2022-05-29T15:50:24.777797Z",
     "shell.execute_reply.started": "2022-05-29T15:50:24.764877Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TrainData(Dataset):\n",
    "    def __init__(self, csv_path, img_path, transform):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_path (string): csv 文件路径\n",
    "            img_path (string): 图像文件所在路径\n",
    "            mode (string): 训练模式还是测试模式\n",
    "            valid_ratio (float): 验证集比例\n",
    "        \"\"\"\n",
    "        self.img_path = img_path\n",
    "        self.data_info = pd.read_csv(csv_path)\n",
    "        self.data_len = len(self.data_info)\n",
    "        self.train_img = np.asarray(self.data_info.iloc[: self.data_len, 0])\n",
    "        self.train_label = np.asarray(self.data_info.iloc[: self.data_len, 1])\n",
    "        self.transform = transform\n",
    "        self.img_arr = self.train_img\n",
    "        self.label_arr = self.train_label\n",
    "        # print(self.img_arr)\n",
    "        # print('*' * 30)\n",
    "        # print(len(self.img_arr))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # print(index)\n",
    "        img_name = self.img_arr[index]\n",
    "        img_as_img = Image.open(os.path.join(self.img_path, f\"{img_name}.png\"))\n",
    "        img_as_tensor = self.transform(img_as_img)\n",
    "        label = self.label_arr[index]\n",
    "        num_label = cls_to_num[label]\n",
    "        return img_as_tensor, num_label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "02bb5cb9-e9ac-4cf6-ab52-dde6b7d77b2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-29T15:50:25.802809Z",
     "iopub.status.busy": "2022-05-29T15:50:25.802230Z",
     "iopub.status.idle": "2022-05-29T15:50:25.812215Z",
     "shell.execute_reply": "2022-05-29T15:50:25.811166Z",
     "shell.execute_reply.started": "2022-05-29T15:50:25.802752Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        model = model\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "\n",
    "# ResNet模型\n",
    "def resnet_model(num_classes, feature_extracting=False):\n",
    "    model = models.resnet18(pretrained=True)\n",
    "    set_parameter_requires_grad(model, feature_extracting)\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Sequential(nn.Linear(num_ftrs, num_classes))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8bd0c4f5-4573-4d5b-9ba1-3104da1af34f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-29T15:50:27.952774Z",
     "iopub.status.busy": "2022-05-29T15:50:27.952185Z",
     "iopub.status.idle": "2022-05-29T15:50:27.959289Z",
     "shell.execute_reply": "2022-05-29T15:50:27.958262Z",
     "shell.execute_reply.started": "2022-05-29T15:50:27.952717Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "        nn.init.xavier_uniform_(m.weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "07071552-05c2-474a-ab30-9a2671506785",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-29T15:50:29.510071Z",
     "iopub.status.busy": "2022-05-29T15:50:29.509376Z",
     "iopub.status.idle": "2022-05-29T15:50:29.521682Z",
     "shell.execute_reply": "2022-05-29T15:50:29.520645Z",
     "shell.execute_reply.started": "2022-05-29T15:50:29.510013Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "transform_train = torchvision.transforms.Compose(\n",
    "    [\n",
    "        # 在高度和宽度上将图像放大到40像素的正方形\n",
    "        torchvision.transforms.Resize(40),\n",
    "        # 随机裁剪出一个高度和宽度均为40像素的正方形图像，\n",
    "        # 生成一个面积为原始图像面积0.64到1倍的小正方形，\n",
    "        # 然后将其缩放为高度和宽度均为32像素的正方形\n",
    "        torchvision.transforms.RandomResizedCrop(\n",
    "            32, scale=(0.64, 1.0), ratio=(1.0, 1.0)\n",
    "        ),\n",
    "        torchvision.transforms.RandomHorizontalFlip(),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        # 标准化图像的每个通道\n",
    "        torchvision.transforms.Normalize(\n",
    "            [0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010]\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "transform_test = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(\n",
    "            [0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010]\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8fea296d-e0db-46b0-861e-9a162c0afcf8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-29T15:50:30.618984Z",
     "iopub.status.busy": "2022-05-29T15:50:30.614285Z",
     "iopub.status.idle": "2022-05-29T15:50:30.651605Z",
     "shell.execute_reply": "2022-05-29T15:50:30.650922Z",
     "shell.execute_reply.started": "2022-05-29T15:50:30.618922Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_path = \"dataset/cifar-10/trainLabels.csv\"\n",
    "train_img_path = \"dataset/cifar-10/train/\"\n",
    "labels_dataframe = pd.read_csv(\"./dataset/cifar-10/trainLabels.csv\")\n",
    "leaves_labels = sorted(list(set(labels_dataframe[\"label\"])))\n",
    "n_classes = len(leaves_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4c2d78be-b2b0-4b24-a9d1-4bf32f2b5165",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-29T15:50:31.428080Z",
     "iopub.status.busy": "2022-05-29T15:50:31.427027Z",
     "iopub.status.idle": "2022-05-29T15:50:31.470693Z",
     "shell.execute_reply": "2022-05-29T15:50:31.470023Z",
     "shell.execute_reply.started": "2022-05-29T15:50:31.428017Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cls_to_num = dict(zip(leaves_labels, range(len(leaves_labels))))\n",
    "num_to_cls = dict(zip(range(len(leaves_labels)), leaves_labels))\n",
    "train_set = TrainData(\n",
    "    csv_path=train_path, img_path=train_img_path, transform=transform_train\n",
    ")\n",
    "ids = np.random.permutation(range(len(labels_dataframe)))\n",
    "split = int(len(labels_dataframe) * 0.9)\n",
    "train_ids, valid_ids = ids[:split], ids[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6bfb5385-17c4-4dda-a183-93583bc23fc1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-29T15:50:32.677447Z",
     "iopub.status.busy": "2022-05-29T15:50:32.676828Z",
     "iopub.status.idle": "2022-05-29T15:50:32.684066Z",
     "shell.execute_reply": "2022-05-29T15:50:32.683059Z",
     "shell.execute_reply.started": "2022-05-29T15:50:32.677393Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_subsampler = torch.utils.data.SubsetRandomSampler(np.array(train_ids))\n",
    "valid_subsampler = torch.utils.data.SubsetRandomSampler(np.array(valid_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9b75efe6-c446-4f0c-9920-66719c4f13eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-29T15:50:33.712368Z",
     "iopub.status.busy": "2022-05-29T15:50:33.711761Z",
     "iopub.status.idle": "2022-05-29T15:50:33.720280Z",
     "shell.execute_reply": "2022-05-29T15:50:33.719243Z",
     "shell.execute_reply.started": "2022-05-29T15:50:33.712284Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "        train_set,\n",
    "        batch_size=128,\n",
    "        sampler=train_subsampler,\n",
    "        num_workers=4,\n",
    "        pin_memory=False,\n",
    "        drop_last=True\n",
    "    )\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "    train_set,\n",
    "    batch_size=128,\n",
    "    sampler=valid_subsampler,\n",
    "    num_workers=4,\n",
    "    pin_memory=False,\n",
    "    drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "77828632-cced-4021-9af6-2405929c00a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-29T15:50:37.303493Z",
     "iopub.status.busy": "2022-05-29T15:50:37.302879Z",
     "iopub.status.idle": "2022-05-29T15:50:37.718350Z",
     "shell.execute_reply": "2022-05-29T15:50:37.717254Z",
     "shell.execute_reply.started": "2022-05-29T15:50:37.303440Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "device, num_epochs, lr, wd = 'cuda', 30, 2e-4, 5e-4\n",
    "lr_period, lr_decay = 4, 0.9\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "model = resnet_model(10)\n",
    "# model.apply(init_weights)\n",
    "model = model.to(device)\n",
    "model.device = device\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=wd)\n",
    "# 线性衰减\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, lr_period, lr_decay)\n",
    "best_acc = 0.\n",
    "# model_path = './models/tiny_cifar.pth'\n",
    "model_path = './models/tiny_cifar_pre.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09eab73e-490d-4ba4-bd95-cbf8a5345035",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-29T15:26:28.682969Z",
     "iopub.status.busy": "2022-05-29T15:26:28.682047Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0\n",
      "******************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:42<00:00,  8.20it/s]\n",
      "100%|██████████| 39/39 [00:06<00:00,  6.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=1\n",
      "******************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 253/351 [00:23<00:08, 11.78it/s]"
     ]
    }
   ],
   "source": [
    "file=open('dataset/cifar-10/report.txt','a')\n",
    "for epoch in range(num_epochs):\n",
    "    # time.sleep(0.5)\n",
    "    model.train()\n",
    "    print(f'{epoch=}')\n",
    "    print(f'Starting epoch {epoch + 1}',file=file,flush=True)\n",
    "    print('*' * 30,file=file,flush=True)\n",
    "    train_loss = []\n",
    "    train_acc = []\n",
    "    cnt=1\n",
    "    for batch in tqdm(train_loader):\n",
    "        # print(f'batch {cnt}')\n",
    "        cnt+=1\n",
    "        time.sleep(0.005)\n",
    "        imgs, labels = batch\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        logits = model(imgs)\n",
    "        loss = loss_function(logits, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # scheduler.step()\n",
    "        train_loss.append(loss.item())\n",
    "    print(\"第%d个epoch的学习率：%f\" % (epoch + 1, optimizer.param_groups[0]['lr']),file=file,flush=True)\n",
    "    scheduler.step()\n",
    "    train_avg_loss = np.sum(train_loss) / len(train_loss)\n",
    "    print(f\"[ Train | {epoch + 1:03d}/{num_epochs:03d} ] loss = {train_avg_loss:.5f}\",file=file,flush=True)\n",
    "    print('Training process has finished. Saving trained model.',file=file,flush=True)\n",
    "    print('Starting validation',file=file,flush=True)\n",
    "    model.eval()\n",
    "    valid_loss = []\n",
    "    valid_acc = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(valid_loader):\n",
    "            time.sleep(.005)\n",
    "            imgs, labels = batch\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            logits = model(imgs)\n",
    "            loss = loss_function(logits, labels)\n",
    "            valid_loss.append(loss.cpu().item())\n",
    "            valid_acc.append((logits.argmax(dim=-1) == labels).float().mean().cpu())\n",
    "        valid_avg_loss = np.sum(valid_loss) / len(valid_loss)\n",
    "        valid_avg_acc = np.sum(valid_acc) / len(valid_acc)\n",
    "        print(f\"[ Valid | {epoch + 1:03d}/{num_epochs:03d} ] loss = {valid_avg_loss:.5f}, acc = {valid_avg_acc:.5f}\"\n",
    "             ,file=file,flush=True)\n",
    "        if valid_avg_acc > best_acc:\n",
    "            best_acc = valid_avg_acc\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            print('saving model with acc {:.3f}'.format(best_acc),file=file,flush=True)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3105dc69-54a6-4ea8-95a8-4d12c4d7b1b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-29T15:50:44.729474Z",
     "iopub.status.busy": "2022-05-29T15:50:44.728854Z",
     "iopub.status.idle": "2022-05-29T15:50:44.739685Z",
     "shell.execute_reply": "2022-05-29T15:50:44.738677Z",
     "shell.execute_reply.started": "2022-05-29T15:50:44.729422Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TestData(Dataset):\n",
    "    def __init__(self, transform):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_path (string): csv 文件路径\n",
    "            img_path (string): 图像文件所在路径\n",
    "            mode (string): 训练模式还是测试模式\n",
    "            valid_ratio (float): 验证集比例\n",
    "        \"\"\"\n",
    "        # self.img_path = img_path\n",
    "        self.transform = transform\n",
    "        # li = []\n",
    "        # for name in os.listdir(img_path):\n",
    "        #     li.append(name)\n",
    "        self.img_arr = img_arr\n",
    "        self.data_len = len(self.img_arr)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_name = self.img_arr[index]\n",
    "        img_as_img = Image.open(os.path.join('dataset/cifar-10/test', img_name))\n",
    "        img_as_tensor = self.transform(img_as_img)\n",
    "        return img_as_tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e73dec22-74b8-456c-93e8-7fc5fd83900e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-29T15:50:47.656736Z",
     "iopub.status.busy": "2022-05-29T15:50:47.656153Z",
     "iopub.status.idle": "2022-05-29T15:50:48.009872Z",
     "shell.execute_reply": "2022-05-29T15:50:48.009106Z",
     "shell.execute_reply.started": "2022-05-29T15:50:47.656689Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['107320.png', '189150.png', '222596.png', '23645.png', '13644.png',\n",
       "       '159622.png', '23232.png', '191419.png', '85702.png', '253221.png'],\n",
       "      dtype='<U10')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li = []\n",
    "for name in os.listdir('dataset/cifar-10/test'):\n",
    "    li.append(name)\n",
    "img_arr=np.array(li)\n",
    "img_arr[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "eccebd29-be09-4567-a75a-b4afe9c0d621",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-29T15:50:50.979998Z",
     "iopub.status.busy": "2022-05-29T15:50:50.979273Z",
     "iopub.status.idle": "2022-05-29T15:50:50.987958Z",
     "shell.execute_reply": "2022-05-29T15:50:50.986405Z",
     "shell.execute_reply.started": "2022-05-29T15:50:50.979927Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_set=TestData(transform=transform_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e72a4d58-1f09-4d85-9a36-4809c2d1d7fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-29T15:50:52.009853Z",
     "iopub.status.busy": "2022-05-29T15:50:52.009243Z",
     "iopub.status.idle": "2022-05-29T15:50:52.018140Z",
     "shell.execute_reply": "2022-05-29T15:50:52.016749Z",
     "shell.execute_reply.started": "2022-05-29T15:50:52.009801Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_loader= torch.utils.data.DataLoader(test_set, batch_size=128, \n",
    "                                         drop_last=False,num_workers=4,pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "35ed2c41-331a-47cc-96d3-3bbd37ff0a5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-29T15:51:13.331773Z",
     "iopub.status.busy": "2022-05-29T15:51:13.331086Z",
     "iopub.status.idle": "2022-05-29T15:54:34.740060Z",
     "shell.execute_reply": "2022-05-29T15:54:34.739210Z",
     "shell.execute_reply.started": "2022-05-29T15:51:13.331711Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2344/2344 [03:19<00:00, 11.77it/s]\n"
     ]
    }
   ],
   "source": [
    "device='cuda'\n",
    "model = resnet_model(10)\n",
    "model = model.to(device)\n",
    "model.device=device\n",
    "model_path='models/tiny_cifar_pre.pth'\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()  #batchnormize用全局的batch算\n",
    "preds = []\n",
    "# img_names=[]\n",
    "for batch in tqdm(test_loader):\n",
    "    imgs = batch\n",
    "    imgs = imgs.to(device)\n",
    "    # img_names.append(name)\n",
    "    with torch.no_grad():\n",
    "        logits = model(imgs)\n",
    "    preds.extend(logits.argmax(dim=-1).cpu().numpy().tolist())\n",
    "labels=[num_to_cls[pred] for pred in preds]\n",
    "num_arr=[img_name.split('.')[0] for img_name in img_arr]\n",
    "df = pd.DataFrame({'id': num_arr, 'label': labels})\n",
    "# df.to_csv('dataset/cifar-10/submission.csv',index=False)\n",
    "df.to_csv('dataset/cifar-10/submission_pre.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319333af-aa83-44e2-b2c8-54e61dff194a",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6863e4-af2b-4fe4-b5b6-2d9733477935",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 1.8",
   "language": "python",
   "name": "torch1.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
