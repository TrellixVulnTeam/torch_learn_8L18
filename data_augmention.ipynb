{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4249de-de8c-456b-b3bf-3447a0608ae9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fddec1c-9a52-4d34-898f-348c24c31aaa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "plt.rcParams['figure.figsize'] = (3.5, 3.5)\n",
    "img = Image.open('./d2l-zh-master/img/cat1.jpg')\n",
    "plt.figure(\"Image\")  # 图像窗口名称\n",
    "plt.imshow(img)\n",
    "plt.axis('off')  # 关掉坐标轴为 off\n",
    "plt.title('image')  # 图像题目\n",
    "plt.show()\n",
    "#\n",
    "# d2l.set_figsize()\n",
    "# img = d2l.Image.open('./d2l-zh-master/img/cat1.jpg')\n",
    "# d2l.plt.imshow(img);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b4ef45-df82-4cb0-839a-a0cec793223c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def apply(img, aug, num_rows=2, num_cols=4, scale=1.5):\n",
    "    Y = [aug(img) for _ in range(num_rows * num_cols)]\n",
    "    d2l.show_images(Y, num_rows, num_cols, scale=scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2fcc05-6a68-4473-bfd0-20c11a391a43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "apply(img, torchvision.transforms.RandomHorizontalFlip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26943d50-6d87-49e5-9ae1-0f65569828d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "type(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee78cd3c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "shape_aug = torchvision.transforms.RandomResizedCrop(size=(200, 200), scale=(0.1, 1), ratio=(0.5, 2))\n",
    "#ratio表示宽高比，scale表示保留像素的比例，size表示最终大小\n",
    "apply(img, shape_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69415cfa",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "apply(img, torchvision.transforms.ColorJitter(brightness=0.5, contrast=0., saturation=0., hue=0.))  #0表示不改"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123db04b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "color_aug = torchvision.transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.5)\n",
    "apply(img, color_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fb222b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "augs = torchvision.transforms.Compose([torchvision.transforms.RandomHorizontalFlip(), color_aug, shape_aug])\n",
    "apply(img, augs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49171e7e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_imgs = torchvision.datasets.CIFAR10(train=True, root='dataset/cifar10', download=True)\n",
    "d2l.show_images([all_imgs[i][0] for i in range(32)], 4, 8, scale=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d9906d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_augs = torchvision.transforms.Compose([torchvision.transforms.RandomHorizontalFlip(), torchvision.transforms.ToTensor()])\n",
    "test_augs = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3a4915",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def loadcifar10(is_train, augs, batch_size):\n",
    "    dataset = torchvision.datasets.CIFAR10(root='dataset/cifar10', train=is_train, download=True, transform=augs)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8854172e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_accuracy_gpu(net, data_iter, device=None):\n",
    "    if isinstance(net, torch.nn.Module):\n",
    "        print('test')\n",
    "        net.eval()\n",
    "        if not device:\n",
    "            device = next(iter(net.parameters())).device\n",
    "    metric = [0, 0]\n",
    "    for X, y in data_iter:\n",
    "        if isinstance(X, list):\n",
    "            X = [x.to(device) for x in X]\n",
    "        else:\n",
    "            X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        with torch.no_grad():\n",
    "            metric[0] += torch.sum(torch.argmax(net(X), dim=1) == y).item()\n",
    "            metric[1] += y.shape[0]\n",
    "        return metric[0] / metric[1]\n",
    "\n",
    "\n",
    "def train_ch13(net, train_iter, test_iter, loss, trainer, num_epochs, device):\n",
    "    def init_weights(m):\n",
    "        if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "    net.apply(init_weights)\n",
    "    print('training on', device)\n",
    "    net.to(device)\n",
    "    num_batches = len(train_iter)\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n = 0.0, 0.0, 0\n",
    "        metric = [0, 0, 0]\n",
    "        net.train()\n",
    "        for i, (X, y) in enumerate(train_iter):\n",
    "            trainer.zero_grad()\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y)\n",
    "            l.sum().backward()\n",
    "            trainer.step()\n",
    "            metric[0] += l.sum().backward() * X.shape[0]\n",
    "            metric[1] += torch.sum(torch.argmax(y_hat, dim=1) == y).item()\n",
    "            metric[2] += y.shape[0]\n",
    "            train_l = metric[0] / metric[2]\n",
    "            train_acc = metric[1] / metric[2]\n",
    "            if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1:\n",
    "                print('epoch %d, batch %d, loss %.4f, train acc %.3f' % (epoch + 1, i + 1, train_l, train_acc))\n",
    "        n += y.shape[0]\n",
    "    test_acc = evaluate_accuracy_gpu(net, test_iter,'cuda')\n",
    "    print(f'loss {train_l:.3f},train acc {train_acc:.3f},test acc {test_acc:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df6ef0e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Residual(nn.Module):\n",
    "    \"\"\"The Residual block of ResNet.\"\"\"\n",
    "\n",
    "    def __init__(self, input_channels, num_channels,\n",
    "                 use_1x1conv=False, strides=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, num_channels,\n",
    "                               kernel_size=3, padding=1, stride=strides)\n",
    "        self.conv2 = nn.Conv2d(num_channels, num_channels,\n",
    "                               kernel_size=3, padding=1)\n",
    "        if use_1x1conv:\n",
    "            self.conv3 = nn.Conv2d(input_channels, num_channels,\n",
    "                                   kernel_size=1, stride=strides)\n",
    "        else:\n",
    "            self.conv3 = None\n",
    "        self.bn1 = nn.BatchNorm2d(num_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(num_channels)\n",
    "\n",
    "    def forward(self, X):\n",
    "        Y = F.relu(self.bn1(self.conv1(X)))\n",
    "        Y = self.bn2(self.conv2(Y))\n",
    "        if self.conv3:\n",
    "            X = self.conv3(X)\n",
    "        Y += X\n",
    "        return F.relu(Y)\n",
    "\n",
    "\n",
    "def resnet18(num_classes, in_channels=1):\n",
    "    \"\"\"A slightly modified ResNet-18 model.\n",
    "\n",
    "    Defined in :numref:`sec_multi_gpu_concise`\"\"\"\n",
    "\n",
    "    def resnet_block(in_channels, out_channels, num_residuals,\n",
    "                     first_block=False):\n",
    "        blk = []\n",
    "        for i in range(num_residuals):\n",
    "            if i == 0 and not first_block:\n",
    "                blk.append(Residual(in_channels, out_channels,\n",
    "                                    use_1x1conv=True, strides=2))\n",
    "            else:\n",
    "                blk.append(Residual(out_channels, out_channels))\n",
    "        return nn.Sequential(*blk)\n",
    "\n",
    "    # This model uses a smaller convolution kernel, stride, and padding and\n",
    "    # removes the maximum pooling layer\n",
    "    net = nn.Sequential(\n",
    "        nn.Conv2d(in_channels, 64, kernel_size=3, stride=1, padding=1),\n",
    "        nn.BatchNorm2d(64),\n",
    "        nn.ReLU())\n",
    "    net.add_module(\"resnet_block1\", resnet_block(64, 64, 2, first_block=True))\n",
    "    net.add_module(\"resnet_block2\", resnet_block(64, 128, 2))\n",
    "    net.add_module(\"resnet_block3\", resnet_block(128, 256, 2))\n",
    "    net.add_module(\"resnet_block4\", resnet_block(256, 512, 2))\n",
    "    net.add_module(\"global_avg_pool\", nn.AdaptiveAvgPool2d((1, 1)))\n",
    "    net.add_module(\"fc\", nn.Sequential(nn.Flatten(), nn.Linear(512, num_classes)))\n",
    "    return net\n",
    "\n",
    "\n",
    "batch_size, devices, net = 256, 'cuda', resnet18(10, 3)\n",
    "\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) in [nn.Linear, nn.Conv2d]:\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "\n",
    "net.apply(init_weights)\n",
    "\n",
    "\n",
    "def train_with_data_aug(train_augs, test_augs, net, lr=0.001):\n",
    "    train_iter = loadcifar10(True, train_augs, batch_size)\n",
    "    test_iter = loadcifar10(False, test_augs, batch_size)\n",
    "    loss = nn.CrossEntropyLoss(reduction=\"none\")\n",
    "    trainer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    train_ch6(net, train_iter, test_iter, loss, trainer, 10, devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f3ba8b-021d-4e4f-885b-93c9732de3ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_with_data_aug(train_augs,test_augs,net,batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ad2cb5-949f-485e-985d-6347897cd713",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (XPython)",
   "language": "python",
   "name": "xpython"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}